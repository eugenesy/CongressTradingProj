{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75db9bfd",
   "metadata": {},
   "source": [
    "Short script to look at price data pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde9469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'data/raw/all_tickers_historical_data.pkl'\n",
    "\n",
    "try:\n",
    "    data = pd.read_pickle(file_path)\n",
    "    \n",
    "    # --- PART 1: Inspecting the Nested 'QCOM' Dictionary ---\n",
    "    print(f\"--- 1. Deep Dive into 'QCOM' ---\")\n",
    "    \n",
    "    if 'QCOM' in data:\n",
    "        qcom_val = data['QCOM']\n",
    "        \n",
    "        # We know qcom_val is a dict, so let's look at its keys\n",
    "        if isinstance(qcom_val, dict):\n",
    "            print(f\"Keys found inside 'QCOM': {list(qcom_val.keys())}\\n\")\n",
    "            \n",
    "            for sub_key, sub_val in qcom_val.items():\n",
    "                print(f\"Key: ['{sub_key}']\")\n",
    "                print(f\"   Type: {type(sub_val)}\")\n",
    "                \n",
    "                # If it's a DataFrame, show columns and first row\n",
    "                if isinstance(sub_val, pd.DataFrame):\n",
    "                    print(f\"   Shape: {sub_val.shape}\")\n",
    "                    print(f\"   Columns: {list(sub_val.columns)}\")\n",
    "                    print(sub_val.head(2).to_string()) # Print first 2 rows clearly\n",
    "                \n",
    "                # If it's a simple value or list, print it directly\n",
    "                else:\n",
    "                    print(f\"   Value: {sub_val}\")\n",
    "                print(\"-\" * 30)\n",
    "    else:\n",
    "        print(\"Key 'QCOM' not found (weird, since we saw it earlier).\")\n",
    "\n",
    "    # --- PART 2: Searching for S&P 500 Keys ---\n",
    "    print(f\"\\n--- 2. Searching for S&P 500 Keys ---\")\n",
    "    \n",
    "    # Common variations for the S&P 500\n",
    "    search_terms = ['sp500', 's&p', 'spx', 'gspc', 'spy', 'index']\n",
    "    found_keys = []\n",
    "\n",
    "    # Case-insensitive search through all top-level keys\n",
    "    for key in data.keys():\n",
    "        key_str = str(key).lower()\n",
    "        if any(term in key_str for term in search_terms):\n",
    "            found_keys.append(key)\n",
    "\n",
    "    if found_keys:\n",
    "        print(f\"Found {len(found_keys)} potential matches:\")\n",
    "        print(found_keys)\n",
    "    else:\n",
    "        print(\"No keys found matching typical S&P 500 terms (sp500, s&p, gspc, spy).\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1168e6d2",
   "metadata": {},
   "source": [
    "Data exploration for the new multiclass labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab98eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data/processed/ml_dataset_with_multiclass_labels.csv...\n",
      "\n",
      "--- Summary Statistics (Full Data) ---\n",
      "                  count          mean           std        3%       50%         97%          min           max\n",
      "performance_1W  32416.0  1.025525e+19  1.846373e+21 -4.150252  0.000000  382.271776 -4234.366422  3.324291e+23\n",
      "performance_2W  32416.0  2.157428e+09  3.861010e+11 -2.370280 -0.005316   40.955893   -88.542772  6.951473e+13\n",
      "performance_1M  32416.0  1.238301e+73  2.229493e+75 -1.497150 -0.011283   10.044790   -13.313260  4.014078e+77\n",
      "performance_2M  32416.0  3.540711e+01  5.616448e+03 -1.100880 -0.017624    4.149672    -4.843071  1.009511e+06\n",
      "performance_3M  32416.0  1.943745e+00  1.624496e+02 -0.940112 -0.016628    2.547790    -2.999390  2.311315e+04\n",
      "performance_6M  32416.0  8.151636e-02  2.275161e+00 -0.742332 -0.015363    1.352727    -1.464731  3.687599e+02\n",
      "performance_8M  32416.0  1.621908e+05  2.920154e+07 -0.703810 -0.016576    1.095628    -1.427931  5.257575e+09\n",
      "performance_1Y  32416.0 -5.002947e-03  4.407729e-01 -0.632800 -0.011550    0.801714    -1.290890  2.143012e+01\n",
      "\n",
      "Generating Linear Plots (Clipped 3%)...\n",
      "Saved: data/processed/dist_linear_clipped.png\n",
      "Generating Logarithmic Plots (Y-Axis Log)...\n",
      "Saved: data/processed/dist_log_scale.png\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display  # For nice table rendering in Jupyter\n",
    "\n",
    "# ================= CONFIGURATION =================\n",
    "FILE_PATH = 'data/processed/ml_dataset_with_multiclass_labels.csv'\n",
    "CLIP_PCT = 0.03  # 3% top/bottom removal for stats & plotting\n",
    "# =================================================\n",
    "\n",
    "def plot_grid(df, cols, title_suffix, log_scale=False, clip_pct=CLIP_PCT):\n",
    "    n_cols = 2\n",
    "    n_rows = (len(cols) + 1) // n_cols\n",
    "    \n",
    "    # Adjust figure size for inline display\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    print(f\"\\n--- {title_suffix} Distributions ---\")\n",
    "    \n",
    "    for i, col in enumerate(cols):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Calculate Clipping Bounds\n",
    "        lower = df[col].quantile(clip_pct)\n",
    "        upper = df[col].quantile(1 - clip_pct)\n",
    "        \n",
    "        # Filter data strictly for plotting\n",
    "        filtered_data = df[(df[col] >= lower) & (df[col] <= upper)][col]\n",
    "        \n",
    "        bins = 100 if log_scale else 50\n",
    "        color = 'teal' if log_scale else 'skyblue'\n",
    "        \n",
    "        sns.histplot(filtered_data, bins=bins, kde=True, ax=ax, color=color)\n",
    "        \n",
    "        if log_scale:\n",
    "            ax.set_yscale('log')\n",
    "            ax.set_ylabel('Frequency (Log Scale)')\n",
    "            ax.set_title(f'{col} (Log Scale)\\nClipped {clip_pct*100:.0f}%-{100 - clip_pct*100:.0f}%')\n",
    "        else:\n",
    "            ax.set_ylabel('Frequency')\n",
    "            ax.set_title(f'{col} (Linear)\\nClipped {clip_pct*100:.0f}%-{100 - clip_pct*100:.0f}%')\n",
    "\n",
    "        ax.set_xlabel('CAGR Outperformance vs SPY')\n",
    "        ax.axvline(0, color='red', linestyle='--', alpha=0.7, label='Market Neutral (0.0)')\n",
    "        ax.legend()\n",
    "\n",
    "    # Hide empty subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(FILE_PATH):\n",
    "        print(f\"Error: File not found at {FILE_PATH}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loading {FILE_PATH}...\")\n",
    "    df = pd.read_csv(FILE_PATH)\n",
    "    \n",
    "    label_cols = [col for col in df.columns if col.startswith('performance_')]\n",
    "    if not label_cols:\n",
    "        print(\"Error: No 'performance_' columns found.\")\n",
    "        return\n",
    "\n",
    "    # --- PART 1: Enhanced Statistics ---\n",
    "    print(\"\\n### Summary Statistics (Full Data vs Trimmed)\")\n",
    "    \n",
    "    # 1. Standard Stats\n",
    "    stats = df[label_cols].describe(percentiles=[CLIP_PCT, 0.5, 1 - CLIP_PCT]).T\n",
    "    \n",
    "    # 2. Calculate Trimmed Mean (removing top/bottom 3%)\n",
    "    trimmed_means = []\n",
    "    for col in label_cols:\n",
    "        q_low = df[col].quantile(CLIP_PCT)\n",
    "        q_high = df[col].quantile(1 - CLIP_PCT)\n",
    "        \n",
    "        # Filter strictly between bounds\n",
    "        trimmed_data = df[(df[col] >= q_low) & (df[col] <= q_high)][col]\n",
    "        trimmed_means.append(trimmed_data.mean())\n",
    "        \n",
    "    # Add to the stats table\n",
    "    trim_col_name = f'Trimmed Mean ({CLIP_PCT*100:.0f}-{100-CLIP_PCT*100:.0f}%)'\n",
    "    stats[trim_col_name] = trimmed_means\n",
    "    \n",
    "    # Reorder columns\n",
    "    display_cols = ['count', 'mean', trim_col_name, \n",
    "                    'std', f'{CLIP_PCT*100:.0f}%', '50%', f'{100-CLIP_PCT*100:.0f}%', 'min', 'max']\n",
    "    \n",
    "    # Display nicely in Notebook\n",
    "    display(stats[display_cols])\n",
    "\n",
    "    # --- PART 2: Plots ---\n",
    "    # Linear\n",
    "    plot_grid(df, label_cols, \"Linear\", log_scale=False, clip_pct=CLIP_PCT)\n",
    "\n",
    "    # Logarithmic\n",
    "    plot_grid(df, label_cols, \"Log Scale\", log_scale=True, clip_pct=CLIP_PCT)\n",
    "\n",
    "# Run directly\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
